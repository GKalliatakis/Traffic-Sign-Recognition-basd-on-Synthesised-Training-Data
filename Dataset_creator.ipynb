{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import os\n",
    "import cv2\n",
    "from skimage import io\n",
    "from skimage import color, exposure, transform\n",
    "from PIL import Image, ImageChops, ImageDraw, ImageOps, ImageFilter, ImageStat, ImageEnhance \n",
    "import imutils\n",
    "import argparse\n",
    "import ntpath\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_paths(directory):\n",
    "    paths = []\n",
    "    for files in os.listdir(directory):\n",
    "        if (files != \".DS_Store\"):\n",
    "            paths.append(directory+'/'+files)\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_borders(img,pix):\n",
    "    borders = []    \n",
    "    for y in range(0,img.size[1]):\n",
    "        found = False\n",
    "        has_grey = False\n",
    "        \n",
    "        for x in range(1,img.size[0]):\n",
    "\n",
    "            r = pix[x,y][0]\n",
    "            g = pix[x,y][1]\n",
    "            b = pix[x,y][2]\n",
    "                \n",
    "            prev_r = pix[x-1,y][0]\n",
    "            prev_g = pix[x-1,y][1]\n",
    "            prev_b = pix[x-1,y][2]\n",
    "            \n",
    "            r_g = abs(r-g)\n",
    "            r_b = abs(r-b)\n",
    "            g_b = abs(g-b)\n",
    "            \n",
    "            if (r_g<=15 and r_b<=15 and g_b<=15):\n",
    "                has_grey = True\n",
    "\n",
    "                \n",
    "            if ((abs(prev_r-r)>=20) or (abs(prev_g-g)>=20) or (abs(prev_b-b)>=20)):\n",
    "                    \n",
    "                for i in range(0,x):\n",
    "                    borders.append([i,y])\n",
    "                found = True\n",
    "                break   \n",
    "            \n",
    "        if ((not found)and(has_grey)):\n",
    "            for i in range(0,img.size[0]-1):\n",
    "                borders.append([i,y])  \n",
    "              \n",
    "        for x in range(img.size[0]-1,1,-1):\n",
    "                \n",
    "            r = pix[x,y][0]\n",
    "            g = pix[x,y][1]\n",
    "            b = pix[x,y][2]\n",
    "                \n",
    "            prev_r = pix[x-1,y][0]\n",
    "            prev_g = pix[x-1,y][1]\n",
    "            prev_b = pix[x-1,y][2]\n",
    "                \n",
    "            if ((abs(prev_r-r)>=20) or (abs(prev_g-g)>=20) or (abs(prev_b-b)>=20)):\n",
    "                    \n",
    "                for i in range(x,img.size[0]-1):\n",
    "                    borders.append([i,y])\n",
    "                break\n",
    "                    \n",
    "    return borders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def manipulate_images(paths):\n",
    "    \n",
    "    for image_path in paths:\n",
    "        \n",
    "        \n",
    "        \n",
    "        img = Image.open(image_path)\n",
    "        pix = img.load()\n",
    "        \n",
    "        borders = find_borders(img,pix)\n",
    "         \n",
    "        \n",
    "        image = cv2.imread(image_path, -1)\n",
    "        \n",
    "        b_channel, g_channel, r_channel = cv2.split(image)\n",
    "        alpha_channel = np.ones(b_channel.shape, dtype=b_channel.dtype) * 255\n",
    "        image_RGBA = cv2.merge((b_channel, g_channel, r_channel, alpha_channel))\n",
    "        \n",
    "        height, width, channels = image.shape\n",
    "        \n",
    "        #Deleting white perimeter of shape\n",
    "        for i in range(0,img.size[0]-1):\n",
    "            image_RGBA[0,i][3] = 0\n",
    "            image_RGBA[img.size[1]-1,i][3] = 0\n",
    "        \n",
    "        for i in range(0,img.size[1]-1):\n",
    "            image_RGBA[i,0][3] = 0\n",
    "            image_RGBA[i,img.size[0]-1][3] = 0\n",
    "            \n",
    "        \n",
    "        \n",
    "        for border in borders:\n",
    "            image_RGBA[border[1],border[0]][3] = 0\n",
    "            \n",
    "        \n",
    "        head, tail = ntpath.split(image_path)\n",
    "        \n",
    "        title,extension = tail.split('.')\n",
    "        cv2.imwrite(\"Traffic_Signs_Templates/Processed_Images/\"+title+\".png\", image_RGBA)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "directory = 'Traffic_Signs_Templates/Images'\n",
    "if (not os.path.exists(\"Traffic_Signs_Templates/Processed_Images\")):\n",
    "    os.mkdir(\"Traffic_Signs_Templates/Processed_Images\")\n",
    "paths = load_paths(directory)\n",
    "manipulate_images(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def img_transform(paths):\n",
    "    \n",
    "    for image_path in paths:\n",
    "        \n",
    "        img = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
    "        rows,cols,ch = img.shape\n",
    "        t = []\n",
    "        for i in range(1,100):\n",
    "            t.append(i)\n",
    "            \n",
    "        \n",
    "        \n",
    "        #EAST FACING\n",
    "        pts1 = np.float32([[cols/10,rows/10],[cols/2,rows/10],[cols/10,rows/2]])\n",
    "        pts2 = np.float32([[cols/5,rows/5],[cols/2,rows/8],[cols/5,rows/1.8]])\n",
    "        M = cv2.getAffineTransform(pts1,pts2)\n",
    "        dst = cv2.warpAffine(img,M,(cols,rows))\n",
    "        \n",
    "        #NORTH-WEST FACING\n",
    "        pts3 = np.float32([[cols*9/10,rows/10],[cols/2,rows/10],[cols*9/10,rows/2]])\n",
    "        pts4 = np.float32([[cols*4.5/5,rows/5],[cols/2,rows/8],[cols*4.5/5,rows/1.8]])\n",
    "        M = cv2.getAffineTransform(pts3,pts4)\n",
    "        dst2 = cv2.warpAffine(img,M,(cols,rows))\n",
    "        \n",
    "        #LEFT TILTED FORWARD FACING\n",
    "        pts5 = np.float32([[cols/10,rows/10],[cols/2,rows/10],[cols/10,rows/2]])\n",
    "        pts6 = np.float32([[cols/12,rows/6],[cols/2.1,rows/8],[cols/10,rows/1.8]])\n",
    "        M = cv2.getAffineTransform(pts5,pts6)\n",
    "        dst3 = cv2.warpAffine(img,M,(cols,rows))\n",
    "        \n",
    "        #RIGHT TILTED FORWARD FACING\n",
    "        pts7 = np.float32([[cols*9/10,rows/10],[cols/2,rows/10],[cols*9/10,rows/2]])\n",
    "        pts8 = np.float32([[cols*10/12,rows/6],[cols/2.2,rows/8],[cols*8.4/10,rows/1.8]])\n",
    "        M = cv2.getAffineTransform(pts7,pts8)\n",
    "        dst4 = cv2.warpAffine(img,M,(cols,rows))\n",
    "        \n",
    "        #WEST FACING\n",
    "        pts9 = np.float32([[cols/10,rows/10],[cols/2,rows/10],[cols*9/10,rows/2]])\n",
    "        pts10 = np.float32([[cols/6,rows/7],[cols/2.2,rows/6],[cols*7/10,rows/1.8]])\n",
    "        M = cv2.getAffineTransform(pts9,pts10)\n",
    "        dst5 = cv2.warpAffine(img,M,(cols,rows))\n",
    "        \n",
    "        #RIGHT TILTED FORWARD FACING\n",
    "        pts11 = np.float32([[cols*9/10,rows/10],[cols/2,rows/10],[cols*9/10,rows/2]])\n",
    "        pts12 = np.float32([[cols*4/6,rows/6],[cols/2.8,rows/8],[cols*7/10,rows/1.8]])\n",
    "        M = cv2.getAffineTransform(pts11,pts12)\n",
    "        dst6 = cv2.warpAffine(img,M,(cols,rows))\n",
    "        \n",
    "        #FORWARD FACING W/ DISTORTION\n",
    "        pts13 = np.float32([[cols/10,rows/10],[cols/2,rows/10],[cols*9/10,rows/2]])\n",
    "        pts14 = np.float32([[cols/8,rows/6],[cols/2.5,rows/6.5],[cols*7/10,rows/1.95]])\n",
    "        M = cv2.getAffineTransform(pts13,pts14)\n",
    "        dst7 = cv2.warpAffine(img,M,(cols,rows))\n",
    "        \n",
    "        #FORWARD FACING W/ DISTORTION 2\n",
    "        pts15 = np.float32([[cols*9/10,rows/10],[cols/2,rows/10],[cols*9/10,rows/2]])\n",
    "        pts16 = np.float32([[cols*4/6,rows/6],[cols/2.5,rows/6.5],[cols*7/10,rows/1.95]])\n",
    "        M = cv2.getAffineTransform(pts15,pts16)\n",
    "        dst8 = cv2.warpAffine(img,M,(cols,rows))\n",
    "        \n",
    "        #FORWARD FACING W/ DISTORTION 3\n",
    "        pts17 = np.float32([[cols*9/10,rows/10],[cols/2,rows/10],[cols*9/10,rows/2]])\n",
    "        pts18 = np.float32([[cols*4.3/6,rows/6.5],[cols/2.4,rows/6.5],[cols*7/10,rows/1.95]])\n",
    "        M = cv2.getAffineTransform(pts17,pts18)\n",
    "        dst9 = cv2.warpAffine(img,M,(cols,rows))\n",
    "        \n",
    "        #FORWARD FACING W/ DISTORTION 4\n",
    "        pts19 = np.float32([[cols*9/10,rows/10],[cols/2,rows/10],[cols*9/10,rows/2]])\n",
    "        pts20 = np.float32([[cols*4.1/6,rows/6.5],[cols/2.65,rows/6.6],[cols*7.1/10,rows/2]])\n",
    "        M = cv2.getAffineTransform(pts19,pts20)\n",
    "        dst10 = cv2.warpAffine(img,M,(cols,rows))\n",
    "         \n",
    "        \n",
    "        #plt.imshow(dst10)\n",
    "        \n",
    "        \n",
    "        head, tail = ntpath.split(image_path)\n",
    "        \n",
    "        title,extension = tail.split('.')\n",
    "        \n",
    "        \n",
    "        cv2.imwrite(\"Traffic_Signs_Templates/Transformed_Images/\"+title+\"/\"+str(t[0])+\".png\",dst)\n",
    "        cv2.imwrite(\"Traffic_Signs_Templates/Transformed_Images/\"+title+\"/\"+str(t[1])+\".png\",dst2)\n",
    "        cv2.imwrite(\"Traffic_Signs_Templates/Transformed_Images/\"+title+\"/\"+str(t[2])+\".png\",dst3)\n",
    "        cv2.imwrite(\"Traffic_Signs_Templates/Transformed_Images/\"+title+\"/\"+str(t[3])+\".png\",dst4)\n",
    "        cv2.imwrite(\"Traffic_Signs_Templates/Transformed_Images/\"+title+\"/\"+str(t[4])+\".png\",dst5)\n",
    "        cv2.imwrite(\"Traffic_Signs_Templates/Transformed_Images/\"+title+\"/\"+str(t[5])+\".png\",dst6)\n",
    "        cv2.imwrite(\"Traffic_Signs_Templates/Transformed_Images/\"+title+\"/\"+str(t[6])+\".png\",dst7)\n",
    "        cv2.imwrite(\"Traffic_Signs_Templates/Transformed_Images/\"+title+\"/\"+str(t[7])+\".png\",dst8)\n",
    "        cv2.imwrite(\"Traffic_Signs_Templates/Transformed_Images/\"+title+\"/\"+str(t[8])+\".png\",dst9)\n",
    "        cv2.imwrite(\"Traffic_Signs_Templates/Transformed_Images/\"+title+\"/\"+str(t[9])+\".png\",dst10)\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "directory = 'Traffic_Signs_Templates/Processed_Images'\n",
    "if (not os.path.exists(\"Traffic_Signs_Templates/Transformed_Images\")):\n",
    "    for path in paths:\n",
    "        head, tail = ntpath.split(path)    \n",
    "        title,extension = tail.split('.')\n",
    "        os.makedirs(\"Traffic_Signs_Templates/Transformed_Images/\"+title)\n",
    "paths = load_paths(directory)\n",
    "img_transform(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_image_exposure(paths,channels):\n",
    "    \n",
    "    exposures = []\n",
    "    \n",
    "    for image_path in paths:\n",
    "        img = Image.open(image_path)\n",
    "        im = Image.open(image_path).convert('LA')\n",
    "        \n",
    "        stat = ImageStat.Stat(im)\n",
    "        \n",
    "        #Average pixel brighness\n",
    "        avg = stat.mean[0]\n",
    "        \n",
    "        #RMS pixel brighness\n",
    "        rms = stat.rms[0]\n",
    "        \n",
    "        stat2 = ImageStat.Stat(img)\n",
    "        \n",
    "        #Consider the number of channels\n",
    "        #background may have RGB while traffic sign has RGBA\n",
    "        if (channels==3):\n",
    "            #Average pixels preceived brightness\n",
    "            r,g,b = stat2.mean\n",
    "            avg_perceived = math.sqrt(0.241*(r**2) + 0.691*(g**2) + 0.068*(b**2))\n",
    "\n",
    "            #RMS pixels perceived brightness\n",
    "            r,g,b = stat2.rms\n",
    "            rms_perceived = math.sqrt(0.241*(r**2) + 0.691*(g**2) + 0.068*(b**2)) \n",
    "\n",
    "            l = [image_path,avg,rms,avg_perceived,rms_perceived]\n",
    "            exposures.append(l)\n",
    "        else:\n",
    "            #Average pixels preceived brightness\n",
    "            r,g,b,a = stat2.mean\n",
    "            avg_perceived = math.sqrt(0.241*(r**2) + 0.691*(g**2) + 0.068*(b**2))\n",
    "\n",
    "            #RMS pixels perceived brightness\n",
    "            r,g,b,a = stat2.rms\n",
    "            rms_perceived = math.sqrt(0.241*(r**2) + 0.691*(g**2) + 0.068*(b**2)) \n",
    "\n",
    "            l = [image_path,avg,rms,avg_perceived,rms_perceived]\n",
    "            exposures.append(l)\n",
    "             \n",
    "\n",
    "    return exposures     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poison_blending(signs_paths,backgrounds_paths):\n",
    "    \n",
    "    background_exposures = find_image_exposure(background_paths,3)\n",
    "    signs_exposures = find_image_exposure(signs_paths,4)\n",
    "    \n",
    "    for sign_path in signs_paths:\n",
    "        \n",
    "        brightness_avrg = 1.0\n",
    "        brightness_rms = 1.0\n",
    "        \n",
    "        peak = Image.open(sign_path).convert('RGBA')\n",
    "        \n",
    "        stat = ImageStat.Stat(peak)\n",
    "        avrg = stat.mean[0]\n",
    "        rms = stat.rms[0]\n",
    "        \n",
    "        while (int(avrg)!=int(background_exposures[0][1])):\n",
    "            if avrg>background_exposures[0][1]:\n",
    "                brightness_avrg = brightness_avrg - 0.001\n",
    "            else:\n",
    "                brightness_avrg = brightness_avrg + 0.001\n",
    "                \n",
    "            enhancer = ImageEnhance.Brightness(peak)\n",
    "            bright = enhancer.enhance(brightness_avrg)\n",
    "            stat = ImageStat.Stat(bright)\n",
    "            avrg = stat.mean[0]\n",
    "            \n",
    "            \n",
    "            \n",
    "        enhancer = ImageEnhance.Brightness(peak)\n",
    "        bright = enhancer.enhance(brightness_avrg)\n",
    "        bright.show()\n",
    "        stat = ImageStat.Stat(bright)\n",
    "        \n",
    "        \n",
    "        while (int(rms)!=int(background_exposures[0][2])):\n",
    "            if rms>background_exposures[0][2]:\n",
    "                brightness_rms = brightness_rms - 0.001\n",
    "            else:\n",
    "                brightness_rms = brightness_rms + 0.001\n",
    "                \n",
    "            enhancer = ImageEnhance.Brightness(peak)\n",
    "            bright = enhancer.enhance(brightness_rms)\n",
    "            stat = ImageStat.Stat(bright)\n",
    "            rms = stat.rms[0]\n",
    "            \n",
    "            \n",
    "        enhancer = ImageEnhance.Brightness(peak)\n",
    "        bright = enhancer.enhance(brightness_rms)\n",
    "        bright.show()\n",
    "        stat = ImageStat.Stat(bright)\n",
    "        \n",
    "        break\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    for background_path in backgrounds_paths:\n",
    "        \n",
    "        background = cv2.imread(background_path)\n",
    "        for sign_path in signs_paths:\n",
    "            \n",
    "            \n",
    "            sign = cv2.imread(sign_path)\n",
    "            \n",
    "            width, height, channels = background.shape\n",
    "            center = (width, height)\n",
    "            \n",
    "            w,h,s = sign.shape\n",
    "            \n",
    "            if (w>width or h>height):\n",
    "                sign = cv2.resize(sign, (width/2, height/2)) \n",
    "            \n",
    "            print background_path\n",
    "            print sign_path\n",
    "            # Create a rough mask around the airplane.\n",
    "            mask = np.zeros(sign.shape, sign.dtype)\n",
    "            poly = np.array([ [(width/2)-(w/2),(height/2)-(h/2)], [(width/2)+(w/2),(height/2)-(h/2)], [(width/2)+(w/2),(height/2)+(h/2)], [(width/2)-(w/2),(height/2)+(h/2)]], np.int32)\n",
    "            cv2.fillPoly(mask, [poly], (255, 255, 255))\n",
    "\n",
    "             \n",
    "            print center\n",
    "            print background.shape\n",
    "            output = cv2.seamlessClone(sign, background, mask, center, cv2.MIXED_CLONE)\n",
    " \n",
    "\n",
    "            cv2.imwrite(\"output.jpg\", output);\n",
    "            break\n",
    "        break\n",
    "    \"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "signs_paths = load_paths(\"Traffic_Signs_Templates/Transformed_Images/1\")\n",
    "background_paths = load_paths(\"Google_search_backgrounds/UK_urban\")\n",
    "poison_blending(signs_paths,background_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
