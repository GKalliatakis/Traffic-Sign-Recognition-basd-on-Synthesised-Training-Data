{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import os\n",
    "import cv2\n",
    "from skimage import io\n",
    "from skimage import color, exposure, transform\n",
    "from PIL import Image, ImageChops, ImageDraw, ImageOps, ImageFilter \n",
    "import imutils\n",
    "import argparse\n",
    "import ntpath\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_templates(directory):\n",
    "    paths = []\n",
    "    for files in os.listdir(directory):\n",
    "        if (files != \".DS_Store\"):\n",
    "            paths.append(directory+'/'+files)\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_borders(img,pix):\n",
    "    borders = []    \n",
    "    for y in range(0,img.size[1]):\n",
    "        found = False\n",
    "        has_grey = False\n",
    "        \n",
    "        for x in range(1,img.size[0]):\n",
    "\n",
    "            r = pix[x,y][0]\n",
    "            g = pix[x,y][1]\n",
    "            b = pix[x,y][2]\n",
    "                \n",
    "            prev_r = pix[x-1,y][0]\n",
    "            prev_g = pix[x-1,y][1]\n",
    "            prev_b = pix[x-1,y][2]\n",
    "            \n",
    "            r_g = abs(r-g)\n",
    "            r_b = abs(r-b)\n",
    "            g_b = abs(g-b)\n",
    "            \n",
    "            if (r_g<=15 and r_b<=15 and g_b<=15):\n",
    "                has_grey = True\n",
    "\n",
    "                \n",
    "            if ((abs(prev_r-r)>=20) or (abs(prev_g-g)>=20) or (abs(prev_b-b)>=20)):\n",
    "                    \n",
    "                for i in range(0,x):\n",
    "                    borders.append([i,y])\n",
    "                found = True\n",
    "                break   \n",
    "            \n",
    "        if ((not found)and(has_grey)):\n",
    "            for i in range(0,img.size[0]-1):\n",
    "                borders.append([i,y])  \n",
    "              \n",
    "        for x in range(img.size[0]-1,1,-1):\n",
    "                \n",
    "            r = pix[x,y][0]\n",
    "            g = pix[x,y][1]\n",
    "            b = pix[x,y][2]\n",
    "                \n",
    "            prev_r = pix[x-1,y][0]\n",
    "            prev_g = pix[x-1,y][1]\n",
    "            prev_b = pix[x-1,y][2]\n",
    "                \n",
    "            if ((abs(prev_r-r)>=20) or (abs(prev_g-g)>=20) or (abs(prev_b-b)>=20)):\n",
    "                    \n",
    "                for i in range(x,img.size[0]-1):\n",
    "                    borders.append([i,y])\n",
    "                break\n",
    "                    \n",
    "    return borders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def manipulate_images(paths):\n",
    "    \n",
    "    for image_path in paths:\n",
    "        \n",
    "        \n",
    "        \n",
    "        img = Image.open(image_path)\n",
    "        pix = img.load()\n",
    "        \n",
    "        borders = find_borders(img,pix)\n",
    "         \n",
    "        \n",
    "        image = cv2.imread(image_path, -1)\n",
    "        \n",
    "        b_channel, g_channel, r_channel = cv2.split(image)\n",
    "        alpha_channel = np.ones(b_channel.shape, dtype=b_channel.dtype) * 255 #creating a dummy alpha channel image.\n",
    "        image_RGBA = cv2.merge((b_channel, g_channel, r_channel, alpha_channel))\n",
    "        \n",
    "        height, width, channels = image.shape\n",
    "        \n",
    "        #Deleting white perimeter of shape\n",
    "        for i in range(0,img.size[0]-1):\n",
    "            image_RGBA[0,i][3] = 0\n",
    "            image_RGBA[img.size[1]-1,i][3] = 0\n",
    "        \n",
    "        for i in range(0,img.size[1]-1):\n",
    "            image_RGBA[i,0][3] = 0\n",
    "            image_RGBA[i,img.size[0]-1][3] = 0\n",
    "            \n",
    "        \n",
    "        \n",
    "        for border in borders:\n",
    "            image_RGBA[border[1],border[0]][3] = 0\n",
    "            \n",
    "        \n",
    "        head, tail = ntpath.split(image_path)\n",
    "        \n",
    "        title,extension = tail.split('.')\n",
    "        cv2.imwrite(\"Traffic_Signs_Templates/Processed_Images/\"+title+\".png\", image_RGBA)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "directory = 'Traffic_Signs_Templates/Images'\n",
    "if (not os.path.exists(\"Traffic_Signs_Templates/Processed_Images\")):\n",
    "    os.mkdir(\"Traffic_Signs_Templates/Processed_Images\")\n",
    "paths = load_templates(directory)\n",
    "manipulate_images(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def img_transform(paths):\n",
    "    \n",
    "    for image_path in paths:\n",
    "        \n",
    "        img = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
    "        rows,cols,ch = img.shape\n",
    "        t = []\n",
    "        for i in range(1,100):\n",
    "            t.append(i)\n",
    "            \n",
    "        \n",
    "        \n",
    "        #EAST FACING\n",
    "        pts1 = np.float32([[cols/10,rows/10],[cols/2,rows/10],[cols/10,rows/2]])\n",
    "        pts2 = np.float32([[cols/5,rows/5],[cols/2,rows/8],[cols/5,rows/1.8]])\n",
    "        M = cv2.getAffineTransform(pts1,pts2)\n",
    "        dst = cv2.warpAffine(img,M,(cols,rows))\n",
    "        \n",
    "        #NORTH-WEST FACING\n",
    "        pts3 = np.float32([[cols*9/10,rows/10],[cols/2,rows/10],[cols*9/10,rows/2]])\n",
    "        pts4 = np.float32([[cols*4.5/5,rows/5],[cols/2,rows/8],[cols*4.5/5,rows/1.8]])\n",
    "        M = cv2.getAffineTransform(pts3,pts4)\n",
    "        dst2 = cv2.warpAffine(img,M,(cols,rows))\n",
    "        \n",
    "        #LEFT TILTED FORWARD FACING\n",
    "        pts5 = np.float32([[cols/10,rows/10],[cols/2,rows/10],[cols/10,rows/2]])\n",
    "        pts6 = np.float32([[cols/12,rows/6],[cols/2.1,rows/8],[cols/10,rows/1.8]])\n",
    "        M = cv2.getAffineTransform(pts5,pts6)\n",
    "        dst3 = cv2.warpAffine(img,M,(cols,rows))\n",
    "        \n",
    "        #RIGHT TILTED FORWARD FACING\n",
    "        pts7 = np.float32([[cols*9/10,rows/10],[cols/2,rows/10],[cols*9/10,rows/2]])\n",
    "        pts8 = np.float32([[cols*10/12,rows/6],[cols/2.2,rows/8],[cols*8.4/10,rows/1.8]])\n",
    "        M = cv2.getAffineTransform(pts7,pts8)\n",
    "        dst4 = cv2.warpAffine(img,M,(cols,rows))\n",
    "        \n",
    "        #WEST FACING\n",
    "        pts9 = np.float32([[cols/10,rows/10],[cols/2,rows/10],[cols*9/10,rows/2]])\n",
    "        pts10 = np.float32([[cols/6,rows/7],[cols/2.2,rows/6],[cols*7/10,rows/1.8]])\n",
    "        M = cv2.getAffineTransform(pts9,pts10)\n",
    "        dst5 = cv2.warpAffine(img,M,(cols,rows))\n",
    "        \n",
    "        #RIGHT TILTED FORWARD FACING\n",
    "        pts11 = np.float32([[cols*9/10,rows/10],[cols/2,rows/10],[cols*9/10,rows/2]])\n",
    "        pts12 = np.float32([[cols*4/6,rows/6],[cols/2.8,rows/8],[cols*7/10,rows/1.8]])\n",
    "        M = cv2.getAffineTransform(pts11,pts12)\n",
    "        dst6 = cv2.warpAffine(img,M,(cols,rows))\n",
    "        \n",
    "        #FORWARD FACING W/ DISTORTION\n",
    "        pts13 = np.float32([[cols/10,rows/10],[cols/2,rows/10],[cols*9/10,rows/2]])\n",
    "        pts14 = np.float32([[cols/8,rows/6],[cols/2.5,rows/6.5],[cols*7/10,rows/1.95]])\n",
    "        M = cv2.getAffineTransform(pts13,pts14)\n",
    "        dst7 = cv2.warpAffine(img,M,(cols,rows))\n",
    "        \n",
    "        #FORWARD FACING W/ DISTORTION 2\n",
    "        pts15 = np.float32([[cols*9/10,rows/10],[cols/2,rows/10],[cols*9/10,rows/2]])\n",
    "        pts16 = np.float32([[cols*4/6,rows/6],[cols/2.5,rows/6.5],[cols*7/10,rows/1.95]])\n",
    "        M = cv2.getAffineTransform(pts15,pts16)\n",
    "        dst8 = cv2.warpAffine(img,M,(cols,rows))\n",
    "        \n",
    "        #FORWARD FACING W/ DISTORTION 3\n",
    "        pts17 = np.float32([[cols*9/10,rows/10],[cols/2,rows/10],[cols*9/10,rows/2]])\n",
    "        pts18 = np.float32([[cols*4.3/6,rows/6.5],[cols/2.4,rows/6.5],[cols*7/10,rows/1.95]])\n",
    "        M = cv2.getAffineTransform(pts17,pts18)\n",
    "        dst9 = cv2.warpAffine(img,M,(cols,rows))\n",
    "        \n",
    "        #FORWARD FACING W/ DISTORTION 4\n",
    "        pts19 = np.float32([[cols*9/10,rows/10],[cols/2,rows/10],[cols*9/10,rows/2]])\n",
    "        pts20 = np.float32([[cols*4.1/6,rows/6.5],[cols/2.65,rows/6.6],[cols*7.1/10,rows/2]])\n",
    "        M = cv2.getAffineTransform(pts19,pts20)\n",
    "        dst10 = cv2.warpAffine(img,M,(cols,rows))\n",
    "         \n",
    "        \n",
    "        #plt.imshow(dst10)\n",
    "        \n",
    "        \n",
    "        head, tail = ntpath.split(image_path)\n",
    "        \n",
    "        title,extension = tail.split('.')\n",
    "        \n",
    "        \n",
    "        cv2.imwrite(\"Traffic_Signs_Templates/Transformed_Images/\"+title+\"/\"+str(t[0])+\".png\",dst)\n",
    "        cv2.imwrite(\"Traffic_Signs_Templates/Transformed_Images/\"+title+\"/\"+str(t[1])+\".png\",dst2)\n",
    "        cv2.imwrite(\"Traffic_Signs_Templates/Transformed_Images/\"+title+\"/\"+str(t[2])+\".png\",dst3)\n",
    "        cv2.imwrite(\"Traffic_Signs_Templates/Transformed_Images/\"+title+\"/\"+str(t[3])+\".png\",dst4)\n",
    "        cv2.imwrite(\"Traffic_Signs_Templates/Transformed_Images/\"+title+\"/\"+str(t[4])+\".png\",dst5)\n",
    "        cv2.imwrite(\"Traffic_Signs_Templates/Transformed_Images/\"+title+\"/\"+str(t[5])+\".png\",dst6)\n",
    "        cv2.imwrite(\"Traffic_Signs_Templates/Transformed_Images/\"+title+\"/\"+str(t[6])+\".png\",dst7)\n",
    "        cv2.imwrite(\"Traffic_Signs_Templates/Transformed_Images/\"+title+\"/\"+str(t[7])+\".png\",dst8)\n",
    "        cv2.imwrite(\"Traffic_Signs_Templates/Transformed_Images/\"+title+\"/\"+str(t[8])+\".png\",dst9)\n",
    "        cv2.imwrite(\"Traffic_Signs_Templates/Transformed_Images/\"+title+\"/\"+str(t[9])+\".png\",dst10)\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'Traffic_Signs_Templates/Processed_Images'\n",
    "if (not os.path.exists(\"Traffic_Signs_Templates/Transformed_Images\")):\n",
    "    for path in paths:\n",
    "        head, tail = ntpath.split(path)    \n",
    "        title,extension = tail.split('.')\n",
    "        os.makedirs(\"Traffic_Signs_Templates/Transformed_Images/\"+title)\n",
    "paths = load_templates(directory)\n",
    "img_transform(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
